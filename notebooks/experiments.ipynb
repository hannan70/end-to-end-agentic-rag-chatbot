{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de745cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary tools\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.llm_math.base import LLMMathChain\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain.callbacks import StreamlitCallbackHandler\n",
    "from langchain.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fa052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variable\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4a9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model='gemma2-9b-it', api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a5dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wikipedia the tools\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"wikipedia\",\n",
    "    func=wikipedia_wrapper.run,\n",
    "    description=\"A tool for retrieving information from Wikipedia about a given topic.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfbaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the math toos\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm)\n",
    "math_tool = Tool(\n",
    "    name=\"llm-math\",\n",
    "    func=llm_math_chain.run,\n",
    "    description=\"An LLM-powered tool for solving mathematical problems, capable of handling complex calculations.\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b5bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANNAN\\AppData\\Local\\Temp\\ipykernel_5968\\2986739058.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search = TavilySearchResults(tavily_api_key=tavily_api_key)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the web search tools\n",
    "web_search = TavilySearchResults(tavily_api_key=tavily_api_key)\n",
    "web_search_tools = Tool(\n",
    "    name=\"web-search\",\n",
    "    func=web_search.run,\n",
    "    description=\"A tool for searching the internet for recent or specific information about a given topic.\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7a7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pormpt = ChatPromptTemplate.from_template(\n",
    "       \"\"\"\n",
    "        You are a smart AI assistant designed to solve user questions using the following tools:\n",
    "        - Wikipedia: For retrieving general knowledge, historical facts, or definitions.\n",
    "        - llm-math: For solving mathematical problems or performing calculations.\n",
    "        - web-search: For answering questions about recent events or information not found on Wikipedia.\n",
    "\n",
    "        Guidelines:\n",
    "        - Use the most appropriate tool based on the question type.\n",
    "        - If the question involves mathematics, use llm-math and present the solution step by step.\n",
    "        - For general knowledge, prefer Wikipedia.\n",
    "        - For current or trending topics, use web-search.\n",
    "\n",
    "        Your task is to solve the user's question and present the answer in a clear, point-wise format.\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03cc8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANNAN\\AppData\\Local\\Temp\\ipykernel_5968\\2344511017.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=pormpt)\n"
     ]
    }
   ],
   "source": [
    "# LLM chain\n",
    "chain = LLMChain(llm=llm, prompt=pormpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b430d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reasoning tools\n",
    "reasoning_tool = Tool(\n",
    "    name=\"reasoning-tool\",\n",
    "    func=chain.run,\n",
    "    description=\"A tool for answering logic-based and reasoning questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34300c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tolls\n",
    "tools = [wikipedia_tool, math_tool, web_search_tools, reasoning_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6fb636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANNAN\\AppData\\Local\\Temp\\ipykernel_5968\\3921542958.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  assistant_agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize agent\n",
    "assistant_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aaeb178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 12 + 8', 'output': '20'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_agent.invoke({\"input\": \"what is 12 + 8\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddc55703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'A box contains 5 red balls and 3 blue balls. How many balls are there in total?',\n",
       " 'output': '8'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_agent.invoke({\"input\": \"A box contains 5 red balls and 3 blue balls. How many balls are there in total?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e1ca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Solve: 15÷3+8×2', 'output': '21.0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_agent.invoke({\"input\": \"Solve: 15÷3+8×2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5b31810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'The perimeter of a rectangle is 50 cm. If the length is 15 cm, what is the width?',\n",
       " 'output': '10 cm'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_agent.invoke({\"input\": \"The perimeter of a rectangle is 50 cm. If the length is 15 cm, what is the width?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5472d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
